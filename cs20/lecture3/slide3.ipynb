{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 议程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Review\n",
    "- Linear regression on birth/life data\n",
    "- Control Flow\n",
    "- tf.data\n",
    "- Optimizers, gradients\n",
    "- Logistic regression on MNIST\n",
    "- Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow将计算的定义与其执行分开\n",
    "\n",
    "阶段1：组装图表\n",
    "\n",
    "阶段2：使用会话在图中执行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = 2\n",
    "y = 3\n",
    "add_op = tf.add(x, y)\n",
    "mul_op = tf.multiply(x, y)\n",
    "useless = tf.multiply(x, add_op)\n",
    "pow_op = tf.pow(add_op, mul_op)\n",
    "writer=tf.summary.FileWriter('./graphs',tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    z = sess.run(pow_op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.constant and tf.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常量值存储在图形定义中\n",
    "\n",
    "会话分配内存来存储变量值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.placeholder and feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用字典（feed_dict）将值提供给占位符\n",
    "\n",
    "易于使用但性能不佳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 避免懒加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分离图形的组合和执行操作\n",
    "- 使用Python属性确保函数仅在第一次调用时加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在TensorFlow中的线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据与模型概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建模之间的线性关系：\n",
    "- 因变量Y.\n",
    "- 解释变量X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "世界发展指标数据集\n",
    "- X: 出生率\n",
    "- Y: 预期寿命\n",
    "\n",
    "190 国家\n",
    "\n",
    "想要：找到X和Y之间的线性关系，从X预测Y.\n",
    "\n",
    "模型：参考: `Y_predicted = w * X + b`\n",
    "\n",
    "均方误差: `E[(y - y_predicted)2]`\n",
    "\n",
    "交互式代码: \n",
    "\n",
    "```python\n",
    "data/birth_life_2010.txt\n",
    "examples/03_linreg_starter.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶段1：组装我们的图表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一步：读数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一种方式读取(官方)\n",
    "def read_data(filename):\n",
    "    '''\n",
    "    读取birth_life_2010.txt 数据\n",
    "    data:返回numpy数组数据\n",
    "    n_samples:例子的数量\n",
    "    '''\n",
    "    # 去掉head\n",
    "    text = open(filename, 'r').readlines()[1:]\n",
    "    # 去掉每一行末尾的换行符\\n，并以制表符\\t进行分隔\n",
    "    data = [line[:-1].split('\\t') for line in text]\n",
    "    # 提取出生率\n",
    "    births = [float(line[1]) for line in data]\n",
    "    # 提取预期寿命\n",
    "    lifes = [float(line[2]) for line in data]\n",
    "    # 变成[(),()]数据\n",
    "    data = list(zip(births, lifes))\n",
    "    # 统计数据量\n",
    "    n_samples = len(data)\n",
    "    # 数据转换为numpy的ndarray类型\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    return data, n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,n_samples=read_data('birth_life_2010.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.822   , 74.82825 ],\n",
       "       [ 3.869   , 70.81949 ],\n",
       "       [ 3.911   , 72.15066 ],\n",
       "       [ 5.578   , 61.999855],\n",
       "       [ 1.579   , 73.92766 ],\n",
       "       [ 4.229   , 67.465195],\n",
       "       [ 1.15    , 81.641464],\n",
       "       [ 3.86    , 72.30639 ],\n",
       "       [ 3.142   , 68.484314],\n",
       "       [ 3.951   , 62.44061 ],\n",
       "       [ 2.16    , 80.70244 ],\n",
       "       [ 2.141   , 76.30168 ],\n",
       "       [ 2.002   , 64.662094],\n",
       "       [ 2.504   , 68.19498 ],\n",
       "       [ 3.451   , 68.76483 ],\n",
       "       [ 2.635   , 74.02456 ],\n",
       "       [ 1.092   , 80.775314],\n",
       "       [ 2.747   , 67.064   ],\n",
       "       [ 1.22    , 80.76195 ],\n",
       "       [ 1.39    , 82.932686],\n",
       "       [ 2.117   , 68.889656],\n",
       "       [ 1.108   , 82.87805 ],\n",
       "       [ 2.47    , 75.99427 ],\n",
       "       [ 2.09    , 75.07688 ],\n",
       "       [ 2.668   , 69.22583 ],\n",
       "       [ 2.022   , 68.53214 ],\n",
       "       [ 1.598   , 73.273094],\n",
       "       [ 2.581   , 62.53622 ],\n",
       "       [ 2.042   , 77.93202 ],\n",
       "       [ 1.92    , 81.69512 ],\n",
       "       [ 2.499   , 68.001   ],\n",
       "       [ 1.94    , 80.402435],\n",
       "       [ 1.445   , 70.27561 ],\n",
       "       [ 2.399   , 64.86351 ],\n",
       "       [ 2.088   , 73.696655],\n",
       "       [ 3.297   , 67.2599  ],\n",
       "       [ 1.5     , 82.24634 ],\n",
       "       [ 1.98    , 81.45122 ],\n",
       "       [ 1.39    , 81.62683 ],\n",
       "       [ 1.57    , 79.42195 ],\n",
       "       [ 1.4     , 75.1122  ],\n",
       "       [ 1.4     , 73.936584],\n",
       "       [ 1.54    , 68.80488 ],\n",
       "       [ 1.38    , 73.458534],\n",
       "       [ 1.32    , 79.02683 ],\n",
       "       [ 1.38    , 76.24634 ],\n",
       "       [ 1.95    , 80.99756 ],\n",
       "       [ 1.79    , 80.70244 ],\n",
       "       [ 1.656   , 74.3111  ],\n",
       "       [ 1.475   , 68.90371 ],\n",
       "       [ 1.422   , 74.61885 ],\n",
       "       [ 1.63    , 80.08781 ],\n",
       "       [ 1.55    , 73.268295],\n",
       "       [ 1.17    , 73.482925],\n",
       "       [ 2.898   , 69.36846 ],\n",
       "       [ 2.2893  , 69.88439 ],\n",
       "       [ 2.59    , 68.295364],\n",
       "       [ 1.4     , 81.73659 ],\n",
       "       [ 2.07    , 80.291954],\n",
       "       [ 2.2     , 81.45122 ],\n",
       "       [ 1.25    , 74.20731 ],\n",
       "       [ 1.44    , 80.3878  ],\n",
       "       [ 1.39    , 79.98781 ],\n",
       "       [ 1.555   , 73.32734 ],\n",
       "       [ 2.      , 81.36829 ],\n",
       "       [ 1.87    , 79.870735],\n",
       "       [ 1.63    , 75.42927 ],\n",
       "       [ 1.87    , 79.1     ],\n",
       "       [ 1.49    , 77.42439 ],\n",
       "       [ 1.476   , 79.380394],\n",
       "       [ 1.46    , 76.47561 ],\n",
       "       [ 1.46    , 79.832   ],\n",
       "       [ 1.49    , 73.51219 ],\n",
       "       [ 1.148   , 75.40044 ],\n",
       "       [ 1.84    , 79.936584],\n",
       "       [ 1.44    , 70.40488 ],\n",
       "       [ 2.3     , 70.506516],\n",
       "       [ 1.44    , 80.38293 ],\n",
       "       [ 1.736   , 73.78356 ],\n",
       "       [ 1.536   , 76.90095 ],\n",
       "       [ 1.8     , 79.18944 ],\n",
       "       [ 2.49    , 74.12732 ],\n",
       "       [ 1.9856  , 76.23683 ],\n",
       "       [ 1.639   , 69.755   ],\n",
       "       [ 1.896   , 75.22212 ],\n",
       "       [ 2.336   , 70.33532 ],\n",
       "       [ 2.064   , 72.11253 ],\n",
       "       [ 1.98    , 74.4399  ],\n",
       "       [ 1.797   , 78.91329 ],\n",
       "       [ 2.501   , 73.76498 ],\n",
       "       [ 2.954   , 72.277   ],\n",
       "       [ 2.484   , 75.97424 ],\n",
       "       [ 2.622   , 73.72922 ],\n",
       "       [ 2.32    , 76.68378 ],\n",
       "       [ 2.329   , 72.84712 ],\n",
       "       [ 3.139   , 72.82593 ],\n",
       "       [ 3.34    , 61.763   ],\n",
       "       [ 2.262   , 69.54915 ],\n",
       "       [ 3.983   , 70.82542 ],\n",
       "       [ 2.235   , 75.66044 ],\n",
       "       [ 2.25    , 71.73237 ],\n",
       "       [ 2.479   , 75.462296],\n",
       "       [ 2.58    , 73.20003 ],\n",
       "       [ 1.467   , 78.96415 ],\n",
       "       [ 1.848   , 79.19261 ],\n",
       "       [ 2.1     , 73.42968 ],\n",
       "       [ 1.862   , 78.885735],\n",
       "       [ 1.83    , 73.09953 ],\n",
       "       [ 3.348   , 66.26856 ],\n",
       "       [ 2.79    , 75.83995 ],\n",
       "       [ 1.551   , 76.57283 ],\n",
       "       [ 1.699   , 74.975174],\n",
       "       [ 2.211   , 75.63215 ],\n",
       "       [ 5.2     , 65.030464],\n",
       "       [ 4.453   , 72.643684],\n",
       "       [ 1.749   , 76.57361 ],\n",
       "       [ 2.04    , 74.6     ],\n",
       "       [ 2.934   , 75.70256 ],\n",
       "       [ 2.811   , 73.85042 ],\n",
       "       [ 2.271   , 78.09759 ],\n",
       "       [ 2.309   , 73.12461 ],\n",
       "       [ 2.279   , 71.86463 ],\n",
       "       [ 1.38    , 80.948784],\n",
       "       [ 2.564   , 74.75312 ],\n",
       "       [ 1.8     , 72.40875 ],\n",
       "       [ 2.295   , 74.60473 ],\n",
       "       [ 3.8     , 73.28966 ],\n",
       "       [ 3.03    , 81.504875],\n",
       "       [ 4.702   , 68.486046],\n",
       "       [ 1.67    , 72.751854],\n",
       "       [ 2.733   , 72.975266],\n",
       "       [ 3.75    , 57.52739 ],\n",
       "       [ 2.54    , 75.02383 ],\n",
       "       [ 2.264   , 72.85254 ],\n",
       "       [ 2.1     , 78.24146 ],\n",
       "       [ 1.677   , 80.797806],\n",
       "       [ 1.764   , 79.288536],\n",
       "       [ 2.313   , 74.72261 ],\n",
       "       [ 3.423   , 65.19885 ],\n",
       "       [ 2.727   , 68.39483 ],\n",
       "       [ 1.752   , 76.551414],\n",
       "       [ 2.625   , 65.13134 ],\n",
       "       [ 2.399   , 66.90885 ],\n",
       "       [ 2.245   , 68.6348  ],\n",
       "       [ 6.288   , 48.282196],\n",
       "       [ 3.29    , 49.860878],\n",
       "       [ 6.258   , 48.455486],\n",
       "       [ 6.149   , 53.614635],\n",
       "       [ 4.072   , 56.588707],\n",
       "       [ 4.896   , 58.160023],\n",
       "       [ 5.544   , 57.38749 ],\n",
       "       [ 3.364   , 48.342804],\n",
       "       [ 4.4     , 61.108242],\n",
       "       [ 2.458   , 52.08149 ],\n",
       "       [ 6.339   , 50.89554 ],\n",
       "       [ 4.982   , 47.402195],\n",
       "       [ 2.5     , 73.03415 ],\n",
       "       [ 4.819   , 58.954075],\n",
       "       [ 5.371   , 55.05712 ],\n",
       "       [ 5.525   , 51.410023],\n",
       "       [ 7.063   , 54.265633],\n",
       "       [ 3.217   , 62.0701  ],\n",
       "       [ 4.912   , 49.696926],\n",
       "       [ 1.47    , 72.967316],\n",
       "       [ 4.533   , 58.21695 ],\n",
       "       [ 6.294   , 50.95483 ],\n",
       "       [ 5.99    , 53.462635],\n",
       "       [ 4.651   , 66.46707 ],\n",
       "       [ 5.238   , 56.147587],\n",
       "       [ 3.199   , 47.365074],\n",
       "       [ 4.718   , 56.497074],\n",
       "       [ 5.063   , 47.700657],\n",
       "       [ 5.246   , 53.638584],\n",
       "       [ 4.17    , 63.83727 ],\n",
       "       [ 3.25    , 62.286682],\n",
       "       [ 4.193   , 58.7151  ],\n",
       "       [ 4.453   , 60.994194],\n",
       "       [ 5.185   , 50.840805],\n",
       "       [ 5.775   , 48.069584],\n",
       "       [ 4.544   , 56.960194],\n",
       "       [ 4.919   , 60.626266],\n",
       "       [ 5.981   , 49.194828],\n",
       "       [ 4.631   , 47.61846 ],\n",
       "       [ 2.405   , 73.77405 ],\n",
       "       [ 4.487   , 51.062756],\n",
       "       [ 4.338   , 49.87722 ],\n",
       "       [ 5.85    , 54.924194],\n",
       "       [ 2.75    , 53.109512],\n",
       "       [ 5.287   , 55.585587],\n",
       "       [ 5.443   , 50.65366 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种方式读取\n",
    "def read_data(file_name):\n",
    "    data = pd.read_table('birth_life_2010.txt')\n",
    "    births = data['Birth rate']\n",
    "    lifes = data['Life expectancy']\n",
    "    data = list(zip(births,lifes))\n",
    "    n_samples = len(data)\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    return data,n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,n_samples=read_data('birth_life_2010.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.822   , 74.82825 ],\n",
       "        [ 3.869   , 70.81949 ],\n",
       "        [ 3.911   , 72.15066 ],\n",
       "        [ 5.578   , 61.999855],\n",
       "        [ 1.579   , 73.92766 ],\n",
       "        [ 4.229   , 67.465195],\n",
       "        [ 1.15    , 81.641464],\n",
       "        [ 3.86    , 72.30639 ],\n",
       "        [ 3.142   , 68.484314],\n",
       "        [ 3.951   , 62.44061 ],\n",
       "        [ 2.16    , 80.70244 ],\n",
       "        [ 2.141   , 76.30168 ],\n",
       "        [ 2.002   , 64.662094],\n",
       "        [ 2.504   , 68.19498 ],\n",
       "        [ 3.451   , 68.76483 ],\n",
       "        [ 2.635   , 74.02456 ],\n",
       "        [ 1.092   , 80.775314],\n",
       "        [ 2.747   , 67.064   ],\n",
       "        [ 1.22    , 80.76195 ],\n",
       "        [ 1.39    , 82.932686],\n",
       "        [ 2.117   , 68.889656],\n",
       "        [ 1.108   , 82.87805 ],\n",
       "        [ 2.47    , 75.99427 ],\n",
       "        [ 2.09    , 75.07688 ],\n",
       "        [ 2.668   , 69.22583 ],\n",
       "        [ 2.022   , 68.53214 ],\n",
       "        [ 1.598   , 73.273094],\n",
       "        [ 2.581   , 62.53622 ],\n",
       "        [ 2.042   , 77.93202 ],\n",
       "        [ 1.92    , 81.69512 ],\n",
       "        [ 2.499   , 68.001   ],\n",
       "        [ 1.94    , 80.402435],\n",
       "        [ 1.445   , 70.27561 ],\n",
       "        [ 2.399   , 64.86351 ],\n",
       "        [ 2.088   , 73.696655],\n",
       "        [ 3.297   , 67.2599  ],\n",
       "        [ 1.5     , 82.24634 ],\n",
       "        [ 1.98    , 81.45122 ],\n",
       "        [ 1.39    , 81.62683 ],\n",
       "        [ 1.57    , 79.42195 ],\n",
       "        [ 1.4     , 75.1122  ],\n",
       "        [ 1.4     , 73.936584],\n",
       "        [ 1.54    , 68.80488 ],\n",
       "        [ 1.38    , 73.458534],\n",
       "        [ 1.32    , 79.02683 ],\n",
       "        [ 1.38    , 76.24634 ],\n",
       "        [ 1.95    , 80.99756 ],\n",
       "        [ 1.79    , 80.70244 ],\n",
       "        [ 1.656   , 74.3111  ],\n",
       "        [ 1.475   , 68.90371 ],\n",
       "        [ 1.422   , 74.61885 ],\n",
       "        [ 1.63    , 80.08781 ],\n",
       "        [ 1.55    , 73.268295],\n",
       "        [ 1.17    , 73.482925],\n",
       "        [ 2.898   , 69.36846 ],\n",
       "        [ 2.2893  , 69.88439 ],\n",
       "        [ 2.59    , 68.295364],\n",
       "        [ 1.4     , 81.73659 ],\n",
       "        [ 2.07    , 80.291954],\n",
       "        [ 2.2     , 81.45122 ],\n",
       "        [ 1.25    , 74.20731 ],\n",
       "        [ 1.44    , 80.3878  ],\n",
       "        [ 1.39    , 79.98781 ],\n",
       "        [ 1.555   , 73.32734 ],\n",
       "        [ 2.      , 81.36829 ],\n",
       "        [ 1.87    , 79.870735],\n",
       "        [ 1.63    , 75.42927 ],\n",
       "        [ 1.87    , 79.1     ],\n",
       "        [ 1.49    , 77.42439 ],\n",
       "        [ 1.476   , 79.380394],\n",
       "        [ 1.46    , 76.47561 ],\n",
       "        [ 1.46    , 79.832   ],\n",
       "        [ 1.49    , 73.51219 ],\n",
       "        [ 1.148   , 75.40044 ],\n",
       "        [ 1.84    , 79.936584],\n",
       "        [ 1.44    , 70.40488 ],\n",
       "        [ 2.3     , 70.506516],\n",
       "        [ 1.44    , 80.38293 ],\n",
       "        [ 1.736   , 73.78356 ],\n",
       "        [ 1.536   , 76.90095 ],\n",
       "        [ 1.8     , 79.18944 ],\n",
       "        [ 2.49    , 74.12732 ],\n",
       "        [ 1.9856  , 76.23683 ],\n",
       "        [ 1.639   , 69.755   ],\n",
       "        [ 1.896   , 75.22212 ],\n",
       "        [ 2.336   , 70.33532 ],\n",
       "        [ 2.064   , 72.11253 ],\n",
       "        [ 1.98    , 74.4399  ],\n",
       "        [ 1.797   , 78.91329 ],\n",
       "        [ 2.501   , 73.76498 ],\n",
       "        [ 2.954   , 72.277   ],\n",
       "        [ 2.484   , 75.97424 ],\n",
       "        [ 2.622   , 73.72922 ],\n",
       "        [ 2.32    , 76.68378 ],\n",
       "        [ 2.329   , 72.84712 ],\n",
       "        [ 3.139   , 72.82593 ],\n",
       "        [ 3.34    , 61.763   ],\n",
       "        [ 2.262   , 69.54915 ],\n",
       "        [ 3.983   , 70.82542 ],\n",
       "        [ 2.235   , 75.66044 ],\n",
       "        [ 2.25    , 71.73237 ],\n",
       "        [ 2.479   , 75.462296],\n",
       "        [ 2.58    , 73.20003 ],\n",
       "        [ 1.467   , 78.96415 ],\n",
       "        [ 1.848   , 79.19261 ],\n",
       "        [ 2.1     , 73.42968 ],\n",
       "        [ 1.862   , 78.885735],\n",
       "        [ 1.83    , 73.09953 ],\n",
       "        [ 3.348   , 66.26856 ],\n",
       "        [ 2.79    , 75.83995 ],\n",
       "        [ 1.551   , 76.57283 ],\n",
       "        [ 1.699   , 74.975174],\n",
       "        [ 2.211   , 75.63215 ],\n",
       "        [ 5.2     , 65.030464],\n",
       "        [ 4.453   , 72.643684],\n",
       "        [ 1.749   , 76.57361 ],\n",
       "        [ 2.04    , 74.6     ],\n",
       "        [ 2.934   , 75.70256 ],\n",
       "        [ 2.811   , 73.85042 ],\n",
       "        [ 2.271   , 78.09759 ],\n",
       "        [ 2.309   , 73.12461 ],\n",
       "        [ 2.279   , 71.86463 ],\n",
       "        [ 1.38    , 80.948784],\n",
       "        [ 2.564   , 74.75312 ],\n",
       "        [ 1.8     , 72.40875 ],\n",
       "        [ 2.295   , 74.60473 ],\n",
       "        [ 3.8     , 73.28966 ],\n",
       "        [ 3.03    , 81.504875],\n",
       "        [ 4.702   , 68.486046],\n",
       "        [ 1.67    , 72.751854],\n",
       "        [ 2.733   , 72.975266],\n",
       "        [ 3.75    , 57.52739 ],\n",
       "        [ 2.54    , 75.02383 ],\n",
       "        [ 2.264   , 72.85254 ],\n",
       "        [ 2.1     , 78.24146 ],\n",
       "        [ 1.677   , 80.797806],\n",
       "        [ 1.764   , 79.288536],\n",
       "        [ 2.313   , 74.72261 ],\n",
       "        [ 3.423   , 65.19885 ],\n",
       "        [ 2.727   , 68.39483 ],\n",
       "        [ 1.752   , 76.551414],\n",
       "        [ 2.625   , 65.13134 ],\n",
       "        [ 2.399   , 66.90885 ],\n",
       "        [ 2.245   , 68.6348  ],\n",
       "        [ 6.288   , 48.282196],\n",
       "        [ 3.29    , 49.860878],\n",
       "        [ 6.258   , 48.455486],\n",
       "        [ 6.149   , 53.614635],\n",
       "        [ 4.072   , 56.588707],\n",
       "        [ 4.896   , 58.160023],\n",
       "        [ 5.544   , 57.38749 ],\n",
       "        [ 3.364   , 48.342804],\n",
       "        [ 4.4     , 61.108242],\n",
       "        [ 2.458   , 52.08149 ],\n",
       "        [ 6.339   , 50.89554 ],\n",
       "        [ 4.982   , 47.402195],\n",
       "        [ 2.5     , 73.03415 ],\n",
       "        [ 4.819   , 58.954075],\n",
       "        [ 5.371   , 55.05712 ],\n",
       "        [ 5.525   , 51.410023],\n",
       "        [ 7.063   , 54.265633],\n",
       "        [ 3.217   , 62.0701  ],\n",
       "        [ 4.912   , 49.696926],\n",
       "        [ 1.47    , 72.967316],\n",
       "        [ 4.533   , 58.21695 ],\n",
       "        [ 6.294   , 50.95483 ],\n",
       "        [ 5.99    , 53.462635],\n",
       "        [ 4.651   , 66.46707 ],\n",
       "        [ 5.238   , 56.147587],\n",
       "        [ 3.199   , 47.365074],\n",
       "        [ 4.718   , 56.497074],\n",
       "        [ 5.063   , 47.700657],\n",
       "        [ 5.246   , 53.638584],\n",
       "        [ 4.17    , 63.83727 ],\n",
       "        [ 3.25    , 62.286682],\n",
       "        [ 4.193   , 58.7151  ],\n",
       "        [ 4.453   , 60.994194],\n",
       "        [ 5.185   , 50.840805],\n",
       "        [ 5.775   , 48.069584],\n",
       "        [ 4.544   , 56.960194],\n",
       "        [ 4.919   , 60.626266],\n",
       "        [ 5.981   , 49.194828],\n",
       "        [ 4.631   , 47.61846 ],\n",
       "        [ 2.405   , 73.77405 ],\n",
       "        [ 4.487   , 51.062756],\n",
       "        [ 4.338   , 49.87722 ],\n",
       "        [ 5.85    , 54.924194],\n",
       "        [ 2.75    , 53.109512],\n",
       "        [ 5.287   , 55.585587],\n",
       "        [ 5.443   , 50.65366 ]], dtype=float32), 190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第2步：为输入和标签创建占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.placeholder(dtype, shape=None, name=None)\n",
    "X,Y=None,None\n",
    "X = tf.placeholder(dtype=tf.float32)\n",
    "Y = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第3步：创建权重和偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.get_variable(name,shape=None,dtype=None,initializer=None,)\n",
    "# w,b,X,Y都是标量，shape=()可设置为shape=[]\n",
    "w,b = None,None\n",
    "w = tf.get_variable(name='weght',shape=(),initializer=tf.zeros_initializer())\n",
    "b = tf.get_variable(name='bias',shape=(),initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第4步：预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted = None\n",
    "Y_predicted = w * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第5步：指定损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = None\n",
    "loss = tf.square(Y - Y_predicted, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第6步：创建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "optimizer = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 阶段2：训练我们的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第7步：初始化及TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # tensorboard\n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg',sess.graph)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第8步：训练模型100个epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:1661.8637834631543\n",
      "Epoch 1:956.3224148609137\n",
      "Epoch 2:844.6737023980994\n",
      "Epoch 3:750.7312486011339\n",
      "Epoch 4:667.6598341012079\n",
      "Epoch 5:594.1417715627896\n",
      "Epoch 6:529.07878103068\n",
      "Epoch 7:471.5004191489204\n",
      "Epoch 8:420.5458626462441\n",
      "Epoch 9:375.45530721966765\n",
      "Epoch 10:335.5543025185697\n",
      "Epoch 11:300.24629857978107\n",
      "Epoch 12:269.00376475843336\n",
      "Epoch 13:241.35957466852116\n",
      "Epoch 14:216.90039135300015\n",
      "Epoch 15:195.25972298129324\n",
      "Epoch 16:176.1137693605349\n",
      "Epoch 17:159.17551693441837\n",
      "Epoch 18:144.1907111125557\n",
      "Epoch 19:130.93503488078713\n",
      "Epoch 20:119.20935661137888\n",
      "Epoch 21:108.8379309807855\n",
      "Epoch 22:99.66466760624593\n",
      "Epoch 23:91.55177013029001\n",
      "Epoch 24:84.37664046781751\n",
      "Epoch 25:78.03217824997724\n",
      "Epoch 26:72.42182927812989\n",
      "Epoch 27:67.46136239485718\n",
      "Epoch 28:63.07566952367442\n",
      "Epoch 29:59.19874146522856\n",
      "Epoch 30:55.77168446383194\n",
      "Epoch 31:52.74269822355127\n",
      "Epoch 32:50.065632780875376\n",
      "Epoch 33:47.70006421631674\n",
      "Epoch 34:45.61017902122909\n",
      "Epoch 35:43.76379750625255\n",
      "Epoch 36:42.13259221098116\n",
      "Epoch 37:40.69221939330516\n",
      "Epoch 38:39.420219863367905\n",
      "Epoch 39:38.297008645340895\n",
      "Epoch 40:37.305591759538146\n",
      "Epoch 41:36.43066341609841\n",
      "Epoch 42:35.658453942681234\n",
      "Epoch 43:34.97724816803575\n",
      "Epoch 44:34.37655378567349\n",
      "Epoch 45:33.84671358035044\n",
      "Epoch 46:33.379665882282545\n",
      "Epoch 47:32.96800991297258\n",
      "Epoch 48:32.60548541990942\n",
      "Epoch 49:32.28618434173986\n",
      "Epoch 50:32.004961317298495\n",
      "Epoch 51:31.757531331044525\n",
      "Epoch 52:31.53978877073019\n",
      "Epoch 53:31.348356819100445\n",
      "Epoch 54:31.180119247269193\n",
      "Epoch 55:31.03225782010038\n",
      "Epoch 56:30.902462910201574\n",
      "Epoch 57:30.78859985760776\n",
      "Epoch 58:30.688725355066556\n",
      "Epoch 59:30.60122861903357\n",
      "Epoch 60:30.524590178362192\n",
      "Epoch 61:30.457532704476954\n",
      "Epoch 62:30.398967422668726\n",
      "Epoch 63:30.34777825418737\n",
      "Epoch 64:30.303121465726413\n",
      "Epoch 65:30.26424930739051\n",
      "Epoch 66:30.230392129550456\n",
      "Epoch 67:30.200964921590334\n",
      "Epoch 68:30.175501555469697\n",
      "Epoch 69:30.153343991707324\n",
      "Epoch 70:30.134226098457216\n",
      "Epoch 71:30.117758308603477\n",
      "Epoch 72:30.103543774372174\n",
      "Epoch 73:30.09139442229674\n",
      "Epoch 74:30.0809388476427\n",
      "Epoch 75:30.07208499982095\n",
      "Epoch 76:30.06452690966084\n",
      "Epoch 77:30.058150938555205\n",
      "Epoch 78:30.05278219980139\n",
      "Epoch 79:30.04828310612785\n",
      "Epoch 80:30.04458791257593\n",
      "Epoch 81:30.041550708114855\n",
      "Epoch 82:30.039046437352113\n",
      "Epoch 83:30.03704103724602\n",
      "Epoch 84:30.03545715799831\n",
      "Epoch 85:30.034288759106282\n",
      "Epoch 86:30.03338805212261\n",
      "Epoch 87:30.032769865304076\n",
      "Epoch 88:30.032386838833535\n",
      "Epoch 89:30.032150670733166\n",
      "Epoch 90:30.032092865493677\n",
      "Epoch 91:30.032186730024037\n",
      "Epoch 92:30.03240725137661\n",
      "Epoch 93:30.032643962397827\n",
      "Epoch 94:30.033039376884087\n",
      "Epoch 95:30.033435566514413\n",
      "Epoch 96:30.033922631802085\n",
      "Epoch 97:30.03442924663878\n",
      "Epoch 98:30.0349335548615\n",
      "Epoch 99:30.03552558278714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # tensorboard\n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg',sess.graph)\n",
    "    # trian the model for 100 epoch\n",
    "    for i in range(100):\n",
    "        # 初始化每一次的loss\n",
    "        total_loss=0\n",
    "        # 每一次，一批批训练\n",
    "        for x,y in data:\n",
    "            # 需要运行优化函数optimizer与loss， Tensorflow 会自动更新weight 和bias 两个变量\n",
    "            _,loss_ = sess.run([optimizer,loss],feed_dict={X:x,Y:y})\n",
    "            total_loss += loss_\n",
    "        print('Epoch {0}:{1}'.format(i,total_loss/n_samples))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第9步：输出w和b的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:1661.8637834631543\n",
      "Epoch 1:956.3224148609137\n",
      "Epoch 2:844.6737023980994\n",
      "Epoch 3:750.7312486011339\n",
      "Epoch 4:667.6598341012079\n",
      "Epoch 5:594.1417715627896\n",
      "Epoch 6:529.07878103068\n",
      "Epoch 7:471.5004191489204\n",
      "Epoch 8:420.5458626462441\n",
      "Epoch 9:375.45530721966765\n",
      "Epoch 10:335.5543025185697\n",
      "Epoch 11:300.24629857978107\n",
      "Epoch 12:269.00376475843336\n",
      "Epoch 13:241.35957466852116\n",
      "Epoch 14:216.90039135300015\n",
      "Epoch 15:195.25972298129324\n",
      "Epoch 16:176.1137693605349\n",
      "Epoch 17:159.17551693441837\n",
      "Epoch 18:144.1907111125557\n",
      "Epoch 19:130.93503488078713\n",
      "Epoch 20:119.20935661137888\n",
      "Epoch 21:108.8379309807855\n",
      "Epoch 22:99.66466760624593\n",
      "Epoch 23:91.55177013029001\n",
      "Epoch 24:84.37664046781751\n",
      "Epoch 25:78.03217824997724\n",
      "Epoch 26:72.42182927812989\n",
      "Epoch 27:67.46136239485718\n",
      "Epoch 28:63.07566952367442\n",
      "Epoch 29:59.19874146522856\n",
      "Epoch 30:55.77168446383194\n",
      "Epoch 31:52.74269822355127\n",
      "Epoch 32:50.065632780875376\n",
      "Epoch 33:47.70006421631674\n",
      "Epoch 34:45.61017902122909\n",
      "Epoch 35:43.76379750625255\n",
      "Epoch 36:42.13259221098116\n",
      "Epoch 37:40.69221939330516\n",
      "Epoch 38:39.420219863367905\n",
      "Epoch 39:38.297008645340895\n",
      "Epoch 40:37.305591759538146\n",
      "Epoch 41:36.43066341609841\n",
      "Epoch 42:35.658453942681234\n",
      "Epoch 43:34.97724816803575\n",
      "Epoch 44:34.37655378567349\n",
      "Epoch 45:33.84671358035044\n",
      "Epoch 46:33.379665882282545\n",
      "Epoch 47:32.96800991297258\n",
      "Epoch 48:32.60548541990942\n",
      "Epoch 49:32.28618434173986\n",
      "Epoch 50:32.004961317298495\n",
      "Epoch 51:31.757531331044525\n",
      "Epoch 52:31.53978877073019\n",
      "Epoch 53:31.348356819100445\n",
      "Epoch 54:31.180119247269193\n",
      "Epoch 55:31.03225782010038\n",
      "Epoch 56:30.902462910201574\n",
      "Epoch 57:30.78859985760776\n",
      "Epoch 58:30.688725355066556\n",
      "Epoch 59:30.60122861903357\n",
      "Epoch 60:30.524590178362192\n",
      "Epoch 61:30.457532704476954\n",
      "Epoch 62:30.398967422668726\n",
      "Epoch 63:30.34777825418737\n",
      "Epoch 64:30.303121465726413\n",
      "Epoch 65:30.26424930739051\n",
      "Epoch 66:30.230392129550456\n",
      "Epoch 67:30.200964921590334\n",
      "Epoch 68:30.175501555469697\n",
      "Epoch 69:30.153343991707324\n",
      "Epoch 70:30.134226098457216\n",
      "Epoch 71:30.117758308603477\n",
      "Epoch 72:30.103543774372174\n",
      "Epoch 73:30.09139442229674\n",
      "Epoch 74:30.0809388476427\n",
      "Epoch 75:30.07208499982095\n",
      "Epoch 76:30.06452690966084\n",
      "Epoch 77:30.058150938555205\n",
      "Epoch 78:30.05278219980139\n",
      "Epoch 79:30.04828310612785\n",
      "Epoch 80:30.04458791257593\n",
      "Epoch 81:30.041550708114855\n",
      "Epoch 82:30.039046437352113\n",
      "Epoch 83:30.03704103724602\n",
      "Epoch 84:30.03545715799831\n",
      "Epoch 85:30.034288759106282\n",
      "Epoch 86:30.03338805212261\n",
      "Epoch 87:30.032769865304076\n",
      "Epoch 88:30.032386838833535\n",
      "Epoch 89:30.032150670733166\n",
      "Epoch 90:30.032092865493677\n",
      "Epoch 91:30.032186730024037\n",
      "Epoch 92:30.03240725137661\n",
      "Epoch 93:30.032643962397827\n",
      "Epoch 94:30.033039376884087\n",
      "Epoch 95:30.033435566514413\n",
      "Epoch 96:30.033922631802085\n",
      "Epoch 97:30.03442924663878\n",
      "Epoch 98:30.0349335548615\n",
      "Epoch 99:30.03552558278714\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # tensorboard\n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg',sess.graph)\n",
    "    # trian the model for 100 epoch\n",
    "    for i in range(100):\n",
    "        # 初始化每一次的loss\n",
    "        total_loss=0\n",
    "        # 每一次，一批批训练\n",
    "        for x,y in data:\n",
    "            # 需要运行优化函数optimizer与loss， Tensorflow 会自动更新weight 和bias 两个变量\n",
    "            _,loss_ = sess.run([optimizer,loss],feed_dict={X:x,Y:y})\n",
    "            total_loss += loss_\n",
    "        print('Epoch {0}:{1}'.format(i,total_loss/n_samples))\n",
    "    writer.close()\n",
    "    # 第9步：输出w和b的值\n",
    "    w_out,b_out = None,None\n",
    "    w_out, b_out = sess.run([w, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第10步：输出耗时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 25.186522 seconds\n",
      "last value of loss, w, b: 30.03552558278714, -6.07021427154541, 84.92951202392578\n"
     ]
    }
   ],
   "source": [
    "print('Took: %f seconds' %(time.time() - start))\n",
    "print('last value of loss, w, b: {0}, {1}, {2}'.format(total_loss/n_samples, w_out, b_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第11步：可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1447e30518>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n",
    "plt.plot(data[:,0], data[:,0] * w_out + b_out, 'r', label='Predicted data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber loss是为了增强平方误差损失函数（squared loss function）对噪声（或叫离群点，outliers）的鲁棒性提出的。\n",
    "\n",
    "对异常值的鲁棒性，如果预测值和实际值之间的差异很小，则将其平方;如果它很大，取其绝对值。\n",
    "\n",
    "定义：\n",
    "\n",
    "\\begin{split}\n",
    "L_\\delta(a)=\\left \\{\n",
    "\\begin{array}{ll}\n",
    "\\frac12a^2,&\\textrm{for } |a|\\leq\\delta,\\\\\n",
    "\\delta\\cdot(|a|-\\frac12\\delta),&\\textrm{otherwise.}\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{split}\n",
    "\n",
    "参数a通常表示residuals，也即(y−y^)或者写作(y−f(x))，当a=y−f(x)时，上述形式可以拓展为： \n",
    "\n",
    "\\begin{split}\n",
    "L_\\delta(y, f(x))=\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\frac12(y-f(x))^2,&\\textrm{for }|y-f(x)|\\leq\\delta\\\\\n",
    "\\delta\\cdot(|y-f(x)|-\\frac12\\delta),&\\textrm{otherwise.}\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 控制流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorFlow中，tf.cond()类似于c语言中的if...else...，用来控制数据流向，但是仅仅类似而已，其中差别还是挺大的。\n",
    "\n",
    "格式：`tf.cond(pred, fn1, fn2, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(label, prediction, delta=14.0):\n",
    "    residual = tf.abs(label - prediction)\n",
    "    def f1(): return 0.5*tf.square(residual)\n",
    "    def f2(): return delta*residual-0.5*tf.square(delta)\n",
    "    return tf.cond(residual < delta, f1,f2)\n",
    "# cond函数分为true和false两种情况。在许多情况下，使用函数tf.case。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码我曾经使用过数据placeholder。但是占位符是一种古老的方式，关于这种方法有各种各样的意见。看来有利于的是，它是一个点，缺点在于它可以很容易地处理数据外的TF较慢处理应被视为一个单独的线程中的数据，和数据瓶颈。因此，这个问题得以解决tf.data。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何使用tf.data?\n",
    "\n",
    "```python\n",
    "tf.data.Dataset.from_tensor_slices((feature, labels))\n",
    "tf.data.Dataset.from_generator(gen, output_types, output_shapes)\n",
    "```\n",
    "\n",
    "\n",
    "`feature`和`labels`必须是Tensor数据类型。但是，由于张量数据类型与numpy数据类型相同，因此可以包含numpy数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 换句话说，如果您从上面的模型中读取数据为tf.data，您可以写：\n",
    "data,n_samples=read_data('birth_life_2010.txt')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), ()), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float32)\n",
      "(TensorShape([]), TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset.output_types) # >> (tf.float32, tf.float32)\n",
    "print(dataset.output_shapes) # >> (TensorShape([]), TensorShape([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.Dataset有几种方法，你可以直接读取数据文件Tensorflow文件格式分析器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data.TextLineDataset(filenames)` 将文件的每一行读作一个数据。它主要用于读取csv文件和机器翻译领域。\n",
    "\n",
    "`tf.data.FixedLengthRecordData(filenames)`它主要用于固定长度数据。数据作为一个数据被接收预定长度。经常使用的地方也经常用于由固定长度组成的数据中。例如，它用于读取诸如CIFAR数据或ImageNet数据之类的内容。\n",
    "\n",
    "`tf.data.TFRecordDataset(filenames)`用于tfrecord格式的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我看到了如何读取数据。现在让我们看一下使用数据。在现有代码中，我们for通过语句逐个使用数据的值。`tf.data.Iterator`使得逐个使用数据变得更加容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data.Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterator = dataset.make_one_shot_iterator()`\n",
    "\n",
    "通过数据集只迭代一次。无需初始化。\n",
    "\n",
    "`iterator = dataset.make_initializable_iterator()`\n",
    "\n",
    "根据需要迭代数据集。需要初始化每个epoch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "X, Y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.822, 74.82825]\n",
      "[3.869, 70.81949]\n",
      "[3.911, 72.15066]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run([X, Y]))\t\t# >> [1.822, 74.82825]\n",
    "    print(sess.run([X, Y]))\t\t# >> [3.869, 70.81949]\n",
    "    print(sess.run([X, Y]))\t\t# >> [3.911, 72.15066]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理TensorFlow中的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.repeat(100)\n",
    "dataset = dataset.batch(128)\n",
    "dataset = dataset.map(lambda x: tf.one_hot(x, 10)) # convert each elem of dataset to one_hot vector\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们应该使用tf.data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于原型设计，feed dict可以更快更容易编写（pythonic）\n",
    "\n",
    "当您有复杂的预处理或多个数据源时，tf.data很难使用\n",
    "\n",
    "NLP数据通常只是一个整数序列。在这种情况下，将数据传输到GPU非常快，因此tf.data的加速并不是那么大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用优化器非常简单。然而只有几行代码可以方便地使用（差分，更新）复杂的配置的优化器。\n",
    "\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y})\n",
    "```\n",
    "会话查看损失所依赖的所有可训练变量并更新它们"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.Variable(initial_value=None, trainable=True,...)`\n",
    "\n",
    "优化程序会自动计算和更新衍生值。因此，它适用于所有相关变量。在某些情况下，可能存在不应更新的变量。在这种变量的情况下，`trainable=False`通过仅将其指定为选项，可以很容易地将其设置为不训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了上面使用的GD opmizer之外，还提供了各种其他优化器作为张量流函数。以下是优化器列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.train.Optimizer\n",
    "- tf.train.GradientDescentOptimizer\n",
    "- tf.train.AdadeltaOptimizer\n",
    "- tf.train.AdagradOptimizer\n",
    "- tf.train.AdagradDAOptimizer\n",
    "- tf.train.MomentumOptimizer\n",
    "- tf.train.AdamOptimizer\n",
    "- tf.train.FtrlOptimizer\n",
    "- tf.train.ProximalGradientDescentOptimizer\n",
    "- tf.train.ProximalAdagradOptimizer\n",
    "- tf.train.RMSPropOptimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
