{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "“一个类似NumPy的数值计算库，支持GPU加速和自动区分，以及灵活的机器学习研究和实验平台。”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启Eager function模式，你不再需要担心：\n",
    "\n",
    "- 占位符\n",
    "- 会话\n",
    "- 控制依赖\n",
    "- “懒加载”\n",
    "- {name，variable，op}范围"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例子1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 未开启Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[1, 1])\n",
    "m = tf.matmul(x, x)\n",
    "print(m)# Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n",
    "with tf.Session() as sess:\n",
    "    m_out = sess.run(m, feed_dict={x: [[2.]]})\n",
    "    print(m_out)# [[4.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开启Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[2.]]  # No need for placeholders!\n",
    "m = tf.matmul(x, x)\n",
    "print(m)  # No sessions!\n",
    "# tf.Tensor([[4.]], shape=(1, 1), dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启用Eager执行后，这3行提供相同的效果。没有会话，没有占位符和matmul操作立即提供值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 未开启Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_uniform([2, 2])\n",
    "with tf.Session() as sess:\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            print(sess.run(x[i, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开启Eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random_uniform([2, 2])\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        print(x[i, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "急切的执行也有助于避免陷入元编程的绊脚石。\n",
    "\n",
    "例如，这里的代码是人们可能在他们的程序中快速破解以分析Tensor x的代码。\n",
    "它很容易被遗漏，但循环的每次迭代都会向图的内存中表示添加操作\n",
    "\n",
    "在这种特殊情况下，还有一个事实是每次调用session.run都在执行random_uniform操作，因此这里的代码片段不会打印张量的一致快照。\n",
    "\n",
    "\n",
    "在启用了急切执行的情况下，没有图形概念或操作的重复执行，因此最明显的处理方式非常有效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors Act Like NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.0, 2.0, 3.0])\n",
    "# Tensors are backed by NumPy arrays\n",
    "assert type(x.numpy()) == np.ndarray\n",
    "squared = np.square(x) # Tensors are compatible with NumPy functions\n",
    " \n",
    "# Tensors are iterable!\n",
    "for i in x:\n",
    "    print(i)\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        print(x[i, j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients(梯度)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启Eager模式后，正向传播很直观很好理解，但应该怎么求梯度呢？\n",
    "\n",
    "在tfe中共有四个函数直接服务于反向传播，它们是：\n",
    "\n",
    "- tfe.gradients_function\n",
    "- tfe.value_and_gradients_function\n",
    "- tfe.implicit_gradients\n",
    "- tfe.implicit_value_and_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "上面四个函数类似于python的装饰器，例如：\n",
    "\n",
    "@tfe.gradients_function\n",
    "def f(x, y):\n",
    "    return x ** 2 + y ** 3\n",
    "f(1., 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "上面就是装饰器函数的一个典型语法，上面可以等价于：\n",
    "def f(x, y):\n",
    "    return x ** 2 + y ** 3\n",
    "g = tfe.gradients_function(f)\n",
    "g(1., 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求导后为：dx=2x,dy=3x^2,则g(1.,2.)=(2,12)\n",
    "\n",
    "`tfe.gradients_function`的输入是一个函数，输出是**输入函数相对于它所有参数的梯度函数**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfe.gradients_function`的功能是**对函数的输入参数求导**，\n",
    "\n",
    "但在实际使用中，我们希望对TensorFlow中的变量（Variable）求导，\n",
    "\n",
    "因为变量中保存的是模型的参数，这才是我们真正要优化、做梯度下降的部分。\n",
    "\n",
    "`tfe.implicit_gradients`的功能就是**生成可以对“计算过程中所有用到的变量”求导的函数**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfe.Variable(initial_value=1.0, name=\"x\")\n",
    "y = tfe.Variable(initial_value=1.0, name=\"y\")\n",
    "def f(t):\n",
    "    return 2 * x * t\n",
    "g = tfe.implicit_gradients(f)\n",
    "g(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面定义两个变量x和y，只用了x这个变量，所以只会对vx求导！g的返回值是一个列表，列表中以(梯度，变量值)的形式存储了所有计算的梯度的值和变量的值。这里就应当是[(2, 1)]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要同时获取f的值和f的梯度，就可以分别用`tfe.value_and_gradients_function`和`tfe.implicit_value_and_gradients`取代`tfe.gradients_function`、`tfe.implicit_gradient`。\n",
    "\n",
    "原先`tfe.gradients_function`返回的是梯度，`tfe.value_and_gradients_function`返回的就是(函数值，梯度)。\n",
    "\n",
    "原先`tfe.implicit_gradient`返回的是(梯度，变量值)，`tfe.implicit_value_and_gradients`返回的就是(函数值，梯度)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将求出的梯度应用到变量上：\n",
    "```python\n",
    "def loss_fn(...):\n",
    "    ....\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "value_and_gradients_fn = tfe.implicit_value_and_gradients(loss_fn)\n",
    "empirical_loss, gradients_and_variables = value_and_gradients_fn(.....)\n",
    "optimizer.apply_gradients(gradients_and_variables)\n",
    "```\n",
    "参考自https://www.zhihu.com/question/67471378/answer/253549074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启Eager模式后用tf.placeholder甚至会直接报错！不能用tf.Variable创建变量，而是要用tf.get_variable()或者tfe.Variable()来创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么时候使用Eager Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 研究员，想要一个灵活的框架\n",
    "    - python控制流和数据结构实现了实验\n",
    "- 开发新模型\n",
    "    - 即时错误报告简化了调试\n",
    "- TensorFlow新手\n",
    "    - 热切的执行使您可以在Python REPL中探索TF API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "“一个类似NumPy的数值计算库，支持GPU加速和自动区分，以及灵活的机器学习研究和实验平台。”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "DATA_FILE = './birth_life_2010.txt'\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0],data[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不能用tf.Variable创建变量，而是要用tf.get_variable()或者tfe.Variable()来创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = tf.Variable(0.0)\n",
    "# b = tf.Variable(0.0)\n",
    "'''\n",
    "tf.Variable not supported when eager execution is enabled. \n",
    "Please use tf.contrib.eager.Variable instead\n",
    "'''\n",
    "w = tfe.Variable(0.0)\n",
    "b = tfe.Variable(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    return x*w+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y,y_predicted):\n",
    "    return (y-y_predicted)**2\n",
    "\n",
    "def huber_loss(y,y_predicted,m=1.0):\n",
    "    t = y-y_predicted\n",
    "    return 0.5*t**2 if tf.abs(t)<=m else m*(tf.abs(t)-0.5*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原先的huber_loss\n",
    "def huber_loss1(label, prediction, delta=14.0):\n",
    "    residual = tf.abs(label - prediction)\n",
    "    def f1(): return 0.5*tf.square(residual)\n",
    "    def f2(): return delta*residual-0.5*tf.square(delta)\n",
    "    return tf.cond(residual < delta, f1,f2)\n",
    "# cond函数分为true和false两种情况。在许多情况下，使用函数tf.case。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss_fn):\n",
    "    print('Training:loss function: ' + loss_fn.__name__)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    def loss_for_example(x,y):\n",
    "        return loss_fn(y,prediction(x))\n",
    "    \n",
    "    # 储存值与梯度\n",
    "    grad_fn = tfe.implicit_value_and_gradients(loss_for_example)\n",
    "    start = time.time()\n",
    "    for epoch in range(100):\n",
    "        total_loss=0.0\n",
    "        for x_i,y_i in tfe.Iterator(dataset):\n",
    "            loss,gradients = grad_fn(x_i,y_i)\n",
    "            optimizer.apply_gradients(gradients)\n",
    "            total_loss+=loss\n",
    "        if epoch%10==0:\n",
    "            print('Epoch {0}:{1}'.format(epoch,total_loss/n_samples))\n",
    "    print('Took:%f seconds'%(time.time()-start))\n",
    "    print('Eager execution exhibits significant overhead per operation. '\n",
    "        'As you increase your batch size, the impact of the overhead will '\n",
    "        'become less noticeable. Eager execution is under active development: '\n",
    "        'expect performance to increase substantially in the near future!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:loss function: huber_loss\n",
      "Epoch 0:60.69637680053711\n",
      "Epoch 10:29.98884391784668\n",
      "Epoch 20:27.12620735168457\n",
      "Epoch 30:24.31956672668457\n",
      "Epoch 40:21.523069381713867\n",
      "Epoch 50:18.747325897216797\n",
      "Epoch 60:16.022245407104492\n",
      "Epoch 70:13.383048057556152\n",
      "Epoch 80:10.830995559692383\n",
      "Epoch 90:8.40764045715332\n",
      "Took:32.411659 seconds\n",
      "Eager execution exhibits significant overhead per operation. As you increase your batch size, the impact of the overhead will become less noticeable. Eager execution is under active development: expect performance to increase substantially in the near future!\n"
     ]
    }
   ],
   "source": [
    "train(huber_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的`.numpy（）`方法检索支持它的NumPy数组。在未来的eager版本中，你不需要调用`.numpy（）`而且会在大多数情况下，能够在NumPy数组所在的地方传递张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7dbae1af60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data[:,0], data[:,0] * w.numpy() + b.numpy(), 'r',\n",
    "         label=\"huber regression\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
