{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow中的卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorFlow中去做卷积，我们有很多内建的层可以使用。你可以输入2维数据做1维卷积，输入3维数据做2维卷积，输入4维数据做3维卷积，最常用的是2维卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 函数模型\n",
    "tf.nn.conv2d(\n",
    "    input,\n",
    "    filter,\n",
    "    strides,\n",
    "    padding,\n",
    "    use_cudnn_on_gpu=True,\n",
    "    data_format='NHWC',\n",
    "    dilations=[1, 1, 1, 1],\n",
    "    name=None)\n",
    "\n",
    "Input: Batch size (N) x Height (H) x Width (W) x Channels (C)\n",
    "Filter: Height x Width x Input Channels x Output Channels\n",
    "(e.g. [5, 5, 3, 64])\n",
    "Strides: 4 element 1-D tensor, strides in each direction\n",
    "(often [1, 1, 1, 1] or [1, 2, 2, 1])\n",
    "Padding: 'SAME' or 'VALID'\n",
    "Dilations: The dilation factor. If set to k > 1, there will be k-1 skipped cells between each filter element on that dimension.\n",
    "Data_format: default to NHWC\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作一个有趣的练习：GitHub中的kernes.py文件中看到一些著名的核的值，在07_run_kernels.py中看到它们的用法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用CNN处理MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第三课中学习了逻辑回归处理MNIST，现在我们使用CNN来处理，看看结果如何！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将采用如下架构：两个步长为1的卷积层，每个卷积层后跟一个relu激活层与最大池化层Maxpool，最后跟两个全连接层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 输入尺寸(W)\n",
    "- 过滤器尺寸(F)\n",
    "- 步长(S)\n",
    "- 零填充(P)\n",
    "\n",
    "在定义函数之前，让我们看一下获取输出大小的公式。当您具有上述输入值时，输出的大小如下所示：\n",
    "\n",
    "$$ \\frac{W-F+2P}{S}+1 $$\n",
    "\n",
    "\n",
    "在我们的MNIST模型中，输入为28x28，滤波器为5x5。并且步幅使用1和填充使用2。因此，输出的大小如下:\n",
    "\n",
    "$$ \\frac{28-5+2\\times2}{1}+1 = 28 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(inputs, filters, k_size, stride, padding, scope_name):\n",
    "    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n",
    "        # rgb通道\n",
    "        in_channels = inputs.shape[-1]\n",
    "        # 卷积核\n",
    "        kernel = tf.get_variable('kernel', [k_size, k_size, in_channels, filters],\n",
    "                                initializer=tf.truncated_normal_initializer())\n",
    "        biases = tf.get_variable('biases', [filters],\n",
    "                            initializer=tf.random_normal_initializer())\n",
    "        # 卷积结果\n",
    "        conv = tf.nn.conv2d(inputs, kernel, strides=[1, stride, stride, 1], padding=padding)\n",
    "    # relu层对卷积结果处理\n",
    "    return tf.nn.relu(conv + biases, name=scope.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.池化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化可减少要素图的维数，提取要素并缩短执行时间。\n",
    "\n",
    "通常使用max-pooling或average-pooling。\n",
    "\n",
    "由于在此模型中使用了max-pooling，因此我们定义了max-pooling函数，如下所示:\n",
    "\n",
    "\n",
    "- 输入尺寸（W）\n",
    "- 池化大小（K）\n",
    "- 池化步长（S）\n",
    "- 池化零填充（P）\n",
    "\n",
    "\n",
    "$$ \\frac{W-K+2P}{S}+1 $$\n",
    "\n",
    "\n",
    "在我们的模型中，输入是28x28，池大小是2x2，补长是2，零填充，所以我们将输出大小如下。\n",
    "\n",
    "$$ \\frac{28-2+2\\times0}{2}+1=14 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool(inputs, ksize, stride, padding='VALID', scope_name='pool'):\n",
    "    with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n",
    "        pool = tf.nn.max_pool(inputs,\n",
    "                            ksize=[1, ksize, ksize, 1],\n",
    "                            strides=[1, stride, stride, 1],\n",
    "                            padding=padding)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
